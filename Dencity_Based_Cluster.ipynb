{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DENCLUE\n",
        "[https://github.com/mgarrett57/DENCLUE/blob/master/denclue.py](https://)"
      ],
      "metadata": {
        "id": "jFTt0S7CjzTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "denclue.py\n",
        "\n",
        "@author: mgarrett\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, ClusterMixin\n",
        "import networkx as nx\n",
        "\n",
        "def _hill_climb(x_t, X, W=None, h=0.1, eps=1e-7):\n",
        "    \"\"\"\n",
        "    This function climbs the 'hill' of the kernel density function\n",
        "    and finds the 'peak', which represents the density attractor\n",
        "    \"\"\"\n",
        "    error = 99.\n",
        "    prob = 0.\n",
        "    x_l1 = np.copy(x_t)\n",
        "\n",
        "    #Sum of the last three steps is used to establish radius\n",
        "    #of neighborhood around attractor. Authors suggested two\n",
        "    #steps works well, but I found three is more robust to\n",
        "    #noisey datasets.\n",
        "    radius_new = 0.\n",
        "    radius_old = 0.\n",
        "    radius_twiceold = 0.\n",
        "    iters = 0.\n",
        "    while True:\n",
        "        radius_thriceold = radius_twiceold\n",
        "        radius_twiceold = radius_old\n",
        "        radius_old = radius_new\n",
        "        x_l0 = np.copy(x_l1)\n",
        "        x_l1, density = _step(x_l0, X, W=W, h=h)\n",
        "        error = density - prob\n",
        "        prob = density\n",
        "        radius_new = np.linalg.norm(x_l1-x_l0)\n",
        "        radius = radius_thriceold + radius_twiceold + radius_old + radius_new\n",
        "        iters += 1\n",
        "        if iters>3 and error < eps:\n",
        "            break\n",
        "    return [x_l1, prob, radius]\n",
        "\n",
        "def _step(x_l0, X, W=None, h=0.1):\n",
        "    n = X.shape[0]\n",
        "    d = X.shape[1]\n",
        "    superweight = 0. #superweight is the kernel X weight for each item\n",
        "    x_l1 = np.zeros((1,d))\n",
        "    if W is None:\n",
        "        W = np.ones((n,1))\n",
        "    else:\n",
        "        W = W\n",
        "    for j in range(n):\n",
        "        kernel = kernelize(x_l0, X[j], h, d)\n",
        "        kernel = kernel * W[j]/(h**d)\n",
        "        superweight = superweight + kernel\n",
        "        x_l1 = x_l1 + (kernel * X[j])\n",
        "    x_l1 = x_l1/superweight\n",
        "    density = superweight/np.sum(W)\n",
        "    return [x_l1, density]\n",
        "\n",
        "def kernelize(x, y, h, degree):\n",
        "    kernel = np.exp(-(np.linalg.norm(x-y)/h)**2./2.)/((2.*np.pi)**(degree/2))\n",
        "    return kernel\n",
        "\n",
        "class DENCLUE(BaseEstimator, ClusterMixin):\n",
        "    \"\"\"Perform DENCLUE clustering from vector array.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    h : float, optional\n",
        "        The smoothing parameter for the gaussian kernel. This is a hyper-\n",
        "        parameter, and the optimal value depends on data. Default is the\n",
        "        np.std(X)/5.\n",
        "\n",
        "    eps : float, optional\n",
        "        Convergence threshold parameter for density attractors\n",
        "\n",
        "    min_density : float, optional\n",
        "        The minimum kernel density required for a cluster attractor to be\n",
        "        considered a cluster and not noise.  Cluster info will stil be kept\n",
        "        but the label for the corresponding instances will be -1 for noise.\n",
        "        Since what consitutes a high enough kernel density depends on the\n",
        "        nature of the data, it's often best to fit the model first and\n",
        "        explore the results before deciding on the min_density, which can be\n",
        "        set later with the 'set_minimum_density' method.\n",
        "        Default is 0.\n",
        "\n",
        "    metric : string, or callable\n",
        "        The metric to use when calculating distance between instances in a\n",
        "        feature array. In this version, I've only tested 'euclidean' at this\n",
        "        moment.\n",
        "\n",
        "    Attributes\n",
        "    -------\n",
        "    cluster_info_ : dictionary [n_clusters]\n",
        "        Contains relevant information of all clusters (i.e. density attractors)\n",
        "        Information is retained even if the attractor is lower than the\n",
        "        minimum density required to be labelled a cluster.\n",
        "\n",
        "    labels_ : array [n_samples]\n",
        "        Cluster labels for each point.  Noisy samples are given the label -1.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "\n",
        "\n",
        "    References\n",
        "    ----------\n",
        "    Hinneburg A., Gabriel HH. \"DENCLUE 2.0: Fast Clustering Based on Kernel\n",
        "    Density Estimation\". In: R. Berthold M., Shawe-Taylor J., Lavrač N. (eds)\n",
        "    Advances in Intelligent Data Analysis VII. IDA 2007\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, h=None, eps=1e-8, min_density=0., metric='euclidean'):\n",
        "        self.h = h\n",
        "        self.eps = eps\n",
        "        self.min_density = min_density\n",
        "        self.metric = metric\n",
        "\n",
        "    def fit(self, X, y=None, sample_weight=None):\n",
        "        if not self.eps > 0.0:\n",
        "            raise ValueError(\"eps must be positive.\")\n",
        "        self.n_samples = X.shape[0]\n",
        "        self.n_features = X.shape[1]\n",
        "        density_attractors = np.zeros((self.n_samples,self.n_features))\n",
        "        radii = np.zeros((self.n_samples,1))\n",
        "        density = np.zeros((self.n_samples,1))\n",
        "\n",
        "        #create default values\n",
        "        if self.h is None:\n",
        "            self.h = np.std(X)/5\n",
        "        if sample_weight is None:\n",
        "            sample_weight = np.ones((self.n_samples,1))\n",
        "        else:\n",
        "            sample_weight = sample_weight\n",
        "\n",
        "        #initialize all labels to noise\n",
        "        labels = -np.ones(X.shape[0])\n",
        "\n",
        "        #climb each hill\n",
        "        for i in range(self.n_samples):\n",
        "            density_attractors[i], density[i], radii[i] = _hill_climb(X[i], X, W=sample_weight,\n",
        "                                                     h=self.h, eps=self.eps)\n",
        "\n",
        "        #initialize cluster graph to finalize clusters. Networkx graph is\n",
        "        #used to verify clusters, which are connected components of the\n",
        "        #graph. Edges are defined as density attractors being in the same\n",
        "        #neighborhood as defined by our radii for each attractor.\n",
        "        cluster_info = {}\n",
        "        num_clusters = 0\n",
        "        cluster_info[num_clusters]={'instances': [0],\n",
        "                                    'centroid': np.atleast_2d(density_attractors[0])}\n",
        "        g_clusters = nx.Graph()\n",
        "        for j1 in range(self.n_samples):\n",
        "            g_clusters.add_node(j1, attr_dict={'attractor':density_attractors[j1], 'radius':radii[j1],\n",
        "                                'density':density[j1]})\n",
        "\n",
        "        #populate cluster graph\n",
        "        for j1 in range(self.n_samples):\n",
        "            for j2 in (x for x in range(self.n_samples) if x != j1):\n",
        "                if g_clusters.has_edge(j1,j2):\n",
        "                    continue\n",
        "                diff = np.linalg.norm(g_clusters.node[j1]['attractor']-g_clusters.node[j2]['attractor'])\n",
        "                if diff <= (g_clusters.node[j1]['radius']+g_clusters.node[j1]['radius']):\n",
        "                    g_clusters.add_edge(j1, j2)\n",
        "\n",
        "        #connected components represent a cluster\n",
        "        clusters = list(nx.connected_component_subgraphs(g_clusters))\n",
        "        num_clusters = 0\n",
        "\n",
        "        #loop through all connected components\n",
        "        for clust in clusters:\n",
        "\n",
        "            #get maximum density of attractors and location\n",
        "            max_instance = max(clust, key=lambda x: clust.node[x]['density'])\n",
        "            max_density = clust.node[max_instance]['density']\n",
        "            max_centroid = clust.node[max_instance]['attractor']\n",
        "\n",
        "\n",
        "            #In Hinneberg, Gabriel (2007), for attractors in a component that\n",
        "            #are not fully connected (i.e. not all attractors are within each\n",
        "            #other's neighborhood), they recommend re-running the hill climb\n",
        "            #with lower eps. From testing, this seems unnecesarry for all but\n",
        "            #special edge cases. Therefore, completeness info is put into\n",
        "            #cluster info dict, but not used to re-run hill climb.\n",
        "            complete = False\n",
        "            c_size = len(clust.nodes())\n",
        "            if clust.number_of_edges() == (c_size*(c_size-1))/2.:\n",
        "                complete = True\n",
        "\n",
        "            #populate cluster_info dict\n",
        "            cluster_info[num_clusters] = {'instances': clust.nodes(),\n",
        "                                        'size': c_size,\n",
        "                                        'centroid': max_centroid,\n",
        "                                        'density': max_density,\n",
        "                                        'complete': complete}\n",
        "\n",
        "            #if the cluster density is not higher than the minimum,\n",
        "            #instances are kept classified as noise\n",
        "            if max_density >= self.min_density:\n",
        "                labels[clust.nodes()]=num_clusters\n",
        "            num_clusters += 1\n",
        "\n",
        "        self.clust_info_ = cluster_info\n",
        "        self.labels_ = labels\n",
        "        return self\n",
        "\n",
        "    def get_density(self, x, X, y=None, sample_weight=None):\n",
        "        superweight=0.\n",
        "        n_samples = X.shape[0]\n",
        "        n_features = X.shape[1]\n",
        "        if sample_weight is None:\n",
        "            sample_weight = np.ones((n_samples,1))\n",
        "        else:\n",
        "            sample_weight = sample_weight\n",
        "        for y in range(n_samples):\n",
        "            kernel = kernelize(x, X[y], h=self.h, degree=n_features)\n",
        "            kernel = kernel * sample_weight[y]/(self.h**n_features)\n",
        "            superweight = superweight + kernel\n",
        "        density = superweight/np.sum(sample_weight)\n",
        "        return density\n",
        "\n",
        "    def set_minimum_density(self, min_density):\n",
        "        self.min_density = min_density\n",
        "        labels_copy = np.copy(self.labels_)\n",
        "        for k in self.clust_info_.keys():\n",
        "            if self.clust_info_[k]['density']<min_density:\n",
        "                labels_copy[self.clust_info_[k]['instances']]= -1\n",
        "            else:\n",
        "                labels_copy[self.clust_info_[k]['instances']]= k\n",
        "        self.labels_ = labels_copy\n",
        "        return self"
      ],
      "metadata": {
        "id": "kNGbo6BNj14g"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}